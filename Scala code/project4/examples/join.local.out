Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/03/24 23:50:54 INFO SparkContext: Running Spark version 1.5.2
21/03/24 23:50:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/03/24 23:50:55 INFO SecurityManager: Changing view acls to: gxj9834
21/03/24 23:50:55 INFO SecurityManager: Changing modify acls to: gxj9834
21/03/24 23:50:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(gxj9834); users with modify permissions: Set(gxj9834)
21/03/24 23:50:56 INFO Slf4jLogger: Slf4jLogger started
21/03/24 23:50:56 INFO Remoting: Starting remoting
21/03/24 23:50:56 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.114.42:46801]
21/03/24 23:50:56 INFO Utils: Successfully started service 'sparkDriver' on port 46801.
21/03/24 23:50:56 INFO SparkEnv: Registering MapOutputTracker
21/03/24 23:50:56 INFO SparkEnv: Registering BlockManagerMaster
21/03/24 23:50:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-879ac2e9-8d60-446a-acea-869419622353
21/03/24 23:50:56 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
21/03/24 23:50:56 INFO HttpFileServer: HTTP File server directory is /tmp/spark-24c5aad2-bdcb-4902-8a84-704bc87b1615/httpd-6048023e-1fde-4ab7-ad9b-eeaa79e920cd
21/03/24 23:50:56 INFO HttpServer: Starting HTTP Server
21/03/24 23:50:56 INFO Utils: Successfully started service 'HTTP file server' on port 41431.
21/03/24 23:50:56 INFO SparkEnv: Registering OutputCommitCoordinator
21/03/24 23:50:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/03/24 23:50:56 INFO SparkUI: Started SparkUI at http://198.202.114.42:4040
21/03/24 23:50:56 INFO SparkContext: Added JAR file:/home/gxj9834/project4/examples/join.jar at http://198.202.114.42:41431/jars/join.jar with timestamp 1616655056436
21/03/24 23:50:56 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
21/03/24 23:50:56 INFO Executor: Starting executor ID driver on host localhost
21/03/24 23:50:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44856.
21/03/24 23:50:56 INFO NettyBlockTransferService: Server created on 44856
21/03/24 23:50:56 INFO BlockManagerMaster: Trying to register BlockManager
21/03/24 23:50:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44856 with 530.0 MB RAM, BlockManagerId(driver, localhost, 44856)
21/03/24 23:50:56 INFO BlockManagerMaster: Registered BlockManager
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(120040) called with curMem=0, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 117.2 KB, free 529.9 MB)
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=120040, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.9 MB)
21/03/24 23:50:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:44856 (size: 12.4 KB, free: 530.0 MB)
21/03/24 23:50:57 INFO SparkContext: Created broadcast 0 from textFile at JoinSpark.scala:8
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(120080) called with curMem=132713, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 117.3 KB, free 529.8 MB)
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=252793, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.8 MB)
21/03/24 23:50:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:44856 (size: 12.4 KB, free: 530.0 MB)
21/03/24 23:50:57 INFO SparkContext: Created broadcast 1 from textFile at JoinSpark.scala:10
21/03/24 23:50:57 INFO FileInputFormat: Total input paths to process : 1
21/03/24 23:50:57 INFO FileInputFormat: Total input paths to process : 1
21/03/24 23:50:57 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
21/03/24 23:50:57 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
21/03/24 23:50:57 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
21/03/24 23:50:57 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
21/03/24 23:50:57 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
21/03/24 23:50:57 INFO SparkContext: Starting job: saveAsTextFile at JoinSpark.scala:14
21/03/24 23:50:57 INFO DAGScheduler: Registering RDD 6 (map at JoinSpark.scala:12)
21/03/24 23:50:57 INFO DAGScheduler: Registering RDD 7 (map at JoinSpark.scala:12)
21/03/24 23:50:57 INFO DAGScheduler: Got job 0 (saveAsTextFile at JoinSpark.scala:14) with 3 output partitions
21/03/24 23:50:57 INFO DAGScheduler: Final stage: ResultStage 2(saveAsTextFile at JoinSpark.scala:14)
21/03/24 23:50:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
21/03/24 23:50:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
21/03/24 23:50:57 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[6] at map at JoinSpark.scala:12), which has no missing parents
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(3688) called with curMem=265466, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 529.8 MB)
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(2138) called with curMem=269154, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.8 MB)
21/03/24 23:50:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:44856 (size: 2.1 KB, free: 530.0 MB)
21/03/24 23:50:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
21/03/24 23:50:57 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[6] at map at JoinSpark.scala:12)
21/03/24 23:50:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
21/03/24 23:50:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at JoinSpark.scala:12), which has no missing parents
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(3632) called with curMem=271292, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 529.7 MB)
21/03/24 23:50:57 INFO MemoryStore: ensureFreeSpace(2101) called with curMem=274924, maxMem=555755765
21/03/24 23:50:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB)
21/03/24 23:50:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:44856 (size: 2.1 KB, free: 530.0 MB)
21/03/24 23:50:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861
21/03/24 23:50:57 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at JoinSpark.scala:12)
21/03/24 23:50:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
21/03/24 23:50:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2191 bytes)
21/03/24 23:50:57 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2191 bytes)
21/03/24 23:50:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/03/24 23:50:57 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
21/03/24 23:50:57 INFO Executor: Fetching http://198.202.114.42:41431/jars/join.jar with timestamp 1616655056436
21/03/24 23:50:57 INFO Utils: Fetching http://198.202.114.42:41431/jars/join.jar to /tmp/spark-24c5aad2-bdcb-4902-8a84-704bc87b1615/userFiles-99e92789-b7cc-435a-9f75-23b6321b14d2/fetchFileTemp2024457211763940060.tmp
21/03/24 23:50:57 INFO Executor: Adding file:/tmp/spark-24c5aad2-bdcb-4902-8a84-704bc87b1615/userFiles-99e92789-b7cc-435a-9f75-23b6321b14d2/join.jar to class loader
21/03/24 23:50:58 INFO HadoopRDD: Input split: file:/home/gxj9834/project4/examples/e.txt:32+32
21/03/24 23:50:58 INFO HadoopRDD: Input split: file:/home/gxj9834/project4/examples/e.txt:0+32
21/03/24 23:50:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2255 bytes result sent to driver
21/03/24 23:50:58 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2255 bytes result sent to driver
21/03/24 23:50:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2191 bytes)
21/03/24 23:50:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
21/03/24 23:50:58 INFO HadoopRDD: Input split: file:/home/gxj9834/project4/examples/d.txt:0+5
21/03/24 23:50:58 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2191 bytes)
21/03/24 23:50:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
21/03/24 23:50:58 INFO HadoopRDD: Input split: file:/home/gxj9834/project4/examples/d.txt:5+5
21/03/24 23:50:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2255 bytes result sent to driver
21/03/24 23:50:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2255 bytes result sent to driver
21/03/24 23:50:58 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 4, localhost, PROCESS_LOCAL, 2191 bytes)
21/03/24 23:50:58 INFO Executor: Running task 2.0 in stage 1.0 (TID 4)
21/03/24 23:50:58 INFO HadoopRDD: Input split: file:/home/gxj9834/project4/examples/d.txt:10+1
21/03/24 23:50:58 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 211 ms on localhost (1/2)
21/03/24 23:50:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 221 ms on localhost (2/2)
21/03/24 23:50:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/03/24 23:50:58 INFO DAGScheduler: ShuffleMapStage 0 (map at JoinSpark.scala:12) finished in 0.242 s
21/03/24 23:50:58 INFO DAGScheduler: looking for newly runnable stages
21/03/24 23:50:58 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
21/03/24 23:50:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/03/24 23:50:58 INFO DAGScheduler: failed: Set()
21/03/24 23:50:58 INFO DAGScheduler: Missing parents for ResultStage 2: List(ShuffleMapStage 1)
21/03/24 23:50:58 INFO Executor: Finished task 2.0 in stage 1.0 (TID 4). 2255 bytes result sent to driver
21/03/24 23:50:58 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 4) in 25 ms on localhost (1/3)
21/03/24 23:50:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 50 ms on localhost (2/3)
21/03/24 23:50:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 40 ms on localhost (3/3)
21/03/24 23:50:58 INFO DAGScheduler: ShuffleMapStage 1 (map at JoinSpark.scala:12) finished in 0.225 s
21/03/24 23:50:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/03/24 23:50:58 INFO DAGScheduler: looking for newly runnable stages
21/03/24 23:50:58 INFO DAGScheduler: running: Set()
21/03/24 23:50:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/03/24 23:50:58 INFO DAGScheduler: failed: Set()
21/03/24 23:50:58 INFO DAGScheduler: Missing parents for ResultStage 2: List()
21/03/24 23:50:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at JoinSpark.scala:14), which is now runnable
21/03/24 23:50:58 INFO MemoryStore: ensureFreeSpace(113320) called with curMem=277025, maxMem=555755765
21/03/24 23:50:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 110.7 KB, free 529.6 MB)
21/03/24 23:50:58 INFO MemoryStore: ensureFreeSpace(38019) called with curMem=390345, maxMem=555755765
21/03/24 23:50:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 37.1 KB, free 529.6 MB)
21/03/24 23:50:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:44856 (size: 37.1 KB, free: 529.9 MB)
21/03/24 23:50:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861
21/03/24 23:50:58 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at JoinSpark.scala:14)
21/03/24 23:50:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks
21/03/24 23:50:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2025 bytes)
21/03/24 23:50:58 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, PROCESS_LOCAL, 2025 bytes)
21/03/24 23:50:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
21/03/24 23:50:58 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/24 23:50:58 INFO FileOutputCommitter: Saved output of task 'attempt_202103242350_0002_m_000000_5' to file:/home/gxj9834/project4/examples/output/_temporary/0/task_202103242350_0002_m_000000
21/03/24 23:50:58 INFO SparkHadoopMapRedUtil: attempt_202103242350_0002_m_000000_5: Committed
21/03/24 23:50:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1165 bytes result sent to driver
21/03/24 23:50:58 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, PROCESS_LOCAL, 2025 bytes)
21/03/24 23:50:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 750 ms on localhost (1/3)
21/03/24 23:50:58 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 3 blocks
21/03/24 23:50:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/03/24 23:50:58 INFO FileOutputCommitter: Saved output of task 'attempt_202103242350_0002_m_000001_6' to file:/home/gxj9834/project4/examples/output/_temporary/0/task_202103242350_0002_m_000001
21/03/24 23:50:58 INFO SparkHadoopMapRedUtil: attempt_202103242350_0002_m_000001_6: Committed
21/03/24 23:50:58 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1165 bytes result sent to driver
21/03/24 23:50:58 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 793 ms on localhost (2/3)
21/03/24 23:50:59 INFO FileOutputCommitter: Saved output of task 'attempt_202103242350_0002_m_000002_7' to file:/home/gxj9834/project4/examples/output/_temporary/0/task_202103242350_0002_m_000002
21/03/24 23:50:59 INFO SparkHadoopMapRedUtil: attempt_202103242350_0002_m_000002_7: Committed
21/03/24 23:50:59 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1165 bytes result sent to driver
21/03/24 23:50:59 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 429 ms on localhost (3/3)
21/03/24 23:50:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/03/24 23:50:59 INFO DAGScheduler: ResultStage 2 (saveAsTextFile at JoinSpark.scala:14) finished in 1.180 s
21/03/24 23:50:59 INFO DAGScheduler: Job 0 finished: saveAsTextFile at JoinSpark.scala:14, took 1.510392 s
21/03/24 23:51:00 INFO SparkUI: Stopped Spark web UI at http://198.202.114.42:4040
21/03/24 23:51:00 INFO DAGScheduler: Stopping DAGScheduler
21/03/24 23:51:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/03/24 23:51:00 INFO MemoryStore: MemoryStore cleared
21/03/24 23:51:00 INFO BlockManager: BlockManager stopped
21/03/24 23:51:00 INFO BlockManagerMaster: BlockManagerMaster stopped
21/03/24 23:51:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/03/24 23:51:00 INFO SparkContext: Successfully stopped SparkContext
21/03/24 23:51:00 INFO ShutdownHookManager: Shutdown hook called
21/03/24 23:51:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-24c5aad2-bdcb-4902-8a84-704bc87b1615
